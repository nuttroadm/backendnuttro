# ü§ñ IAs Gratuitas para Teste - Alternativas ao Gemini

## ‚ö†Ô∏è Problema Atual

O Gemini 2.0 Flash est√° com **quota excedida** (429 errors). A conta free tier tem limite muito baixo.

## ‚úÖ Op√ß√µes Gratuitas Recomendadas

### **1. Groq (Recomendado)** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Por qu√™:**
- ‚úÖ **Totalmente gratuito** (sem cart√£o de cr√©dito)
- ‚úÖ **Muito r√°pido** (infer√™ncia ultra-r√°pida)
- ‚úÖ **Sem limites r√≠gidos** (generoso para testes)
- ‚úÖ **Suporta modelos Llama 3, Mixtral, etc.**

**Como usar:**
```python
# Instalar
pip install langchain-groq

# Configurar
from langchain_groq import ChatGroq

llm = ChatGroq(
    groq_api_key="sua-chave",
    model_name="llama-3.1-70b-versatile"  # ou "mixtral-8x7b-32768"
)
```

**Obter chave:** https://console.groq.com/keys

---

### **2. Hugging Face Inference API** ‚≠ê‚≠ê‚≠ê‚≠ê

**Por qu√™:**
- ‚úÖ **Gratuito** (com limites generosos)
- ‚úÖ **Muitos modelos** dispon√≠veis
- ‚úÖ **Boa qualidade**

**Como usar:**
```python
# Instalar
pip install langchain-huggingface

# Configurar
from langchain_huggingface import ChatHuggingFace

llm = ChatHuggingFace(
    huggingfacehub_api_token="sua-chave",
    repo_id="meta-llama/Llama-3.1-8B-Instruct"
)
```

**Obter chave:** https://huggingface.co/settings/tokens

---

### **3. Together AI** ‚≠ê‚≠ê‚≠ê‚≠ê

**Por qu√™:**
- ‚úÖ **Cr√©ditos gratuitos** ($25 ao se registrar)
- ‚úÖ **Modelos de alta qualidade**
- ‚úÖ **Boa performance**

**Como usar:**
```python
# Instalar
pip install langchain-together

# Configurar
from langchain_together import ChatTogether

llm = ChatTogether(
    together_api_key="sua-chave",
    model="meta-llama/Llama-3-70b-chat-hf"
)
```

**Obter chave:** https://api.together.xyz/settings/api-keys

---

### **4. Ollama (Local)** ‚≠ê‚≠ê‚≠ê

**Por qu√™:**
- ‚úÖ **100% gratuito** (roda localmente)
- ‚úÖ **Sem limites**
- ‚úÖ **Privacidade total**

**Desvantagens:**
- ‚ö†Ô∏è Requer instala√ß√£o local
- ‚ö†Ô∏è Pode ser mais lento
- ‚ö†Ô∏è Consome recursos do servidor

**Como usar:**
```python
# Instalar Ollama localmente primeiro
# https://ollama.ai/download

# Depois usar
from langchain_community.llms import Ollama

llm = Ollama(model="llama3")
```

---

### **5. OpenRouter (Free Tier)** ‚≠ê‚≠ê‚≠ê

**Por qu√™:**
- ‚úÖ **Modelos gratuitos** dispon√≠veis
- ‚úÖ **F√°cil integra√ß√£o**
- ‚úÖ **Boa documenta√ß√£o**

**Limita√ß√µes:**
- ‚ö†Ô∏è Limites de rate
- ‚ö†Ô∏è Alguns modelos s√£o pagos

**Como usar:**
```python
# J√° est√° configurado no c√≥digo
# Apenas mudar a chave e modelo
```

---

## üéØ Recomenda√ß√£o Final

**Para testes r√°pidos:** **Groq** (mais r√°pido e generoso)

**Para produ√ß√£o futura:** **Together AI** ou **Hugging Face** (mais est√°vel)

---

## üìù Pr√≥ximos Passos

1. Escolher uma das op√ß√µes acima
2. Obter a chave API
3. Atualizar `ai_agents.py` para usar a nova IA
4. Testar funcionalidades

Qual voc√™ prefere? Recomendo **Groq** para come√ßar!

